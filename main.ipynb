{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('mnist_test.csv')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "class LossFunction:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def loss(self, a : np.ndarray):\n",
    "        prob = sigmoid(np.dot(self.X, a))\n",
    "        values = - self.y * np.log(prob) - (1 - self.y) * np.log(1 - prob)\n",
    "        return np.nansum(values) / self.y.shape[0]\n",
    "\n",
    "    def gradient(self, a : np.ndarray):\n",
    "        prob = sigmoid(np.dot(self.X, a))\n",
    "        sub_coefficient = -(self.y - prob) \n",
    "        return np.dot(self.X.T, sub_coefficient) / self.y.shape[0]\n",
    "    \n",
    "    def precision(self, a : np.ndarray):\n",
    "        prob = sigmoid(np.dot(self.X, a))\n",
    "        prob = np.array(prob >= 0.5, dtype=np.int32)\n",
    "        return np.sum(prob == self.y) / self.y.shape[0]\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 785), (10000,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('label', axis=1).values\n",
    "# X: shape m x 784\n",
    "#append a column of 1s\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "y = data['label'].values\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = []\n",
    "for digit in range(10):\n",
    "    y_digit = np.array(y == digit, dtype=np.int32)\n",
    "    loss_functions.append(LossFunction(X, y_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(loss_func, starting_point, learning_rate = 0.00001, num_steps = 40, precision=0.00001):\n",
    "    cur_point = starting_point\n",
    "    for i in range(num_steps):\n",
    "        grad = loss_func.gradient(cur_point)\n",
    "        # print(\"Iteration {}: loss = {}, precision = {}\".format(i, loss_func.loss(cur_point), loss_func.precision(cur_point)))\n",
    "        cur_point = cur_point - learning_rate * grad\n",
    "        if np.linalg.norm(grad) < precision:\n",
    "            break\n",
    "    return cur_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for digit 0: 0.9875\n",
      "Accuracy for digit 1: 0.9889\n",
      "Accuracy for digit 2: 0.9711\n",
      "Accuracy for digit 3: 0.9666\n",
      "Accuracy for digit 4: 0.972\n",
      "Accuracy for digit 5: 0.957\n",
      "Accuracy for digit 6: 0.9784\n",
      "Accuracy for digit 7: 0.9791\n",
      "Accuracy for digit 8: 0.9348\n",
      "Accuracy for digit 9: 0.949\n"
     ]
    }
   ],
   "source": [
    "optimal_points = []\n",
    "\n",
    "for digit in range(10):\n",
    "    optimal_point = gradient_descent(loss_functions[digit], np.zeros(X.shape[1]))\n",
    "    print(\"Accuracy for digit {}: {}\".format(digit, loss_functions[digit].precision(optimal_point)))\n",
    "    optimal_points.append(optimal_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(X, optimal_points):\n",
    "    prob = np.zeros((X.shape[0], 10))\n",
    "    for digit in range(10):\n",
    "        prob[:, digit] = sigmoid(np.dot(X, optimal_points[digit]))\n",
    "    return np.argmax(prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_digit(data, row_id):\n",
    "    row = data.iloc[row_id]\n",
    "    label = row['label']\n",
    "    image = row.drop('label').values.reshape(28, 28)\n",
    "    plt.title('Digit Label = {}'.format(label))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('mnist_test.csv')\n",
    "X_test = data_test.drop('label', axis=1).values\n",
    "X_test = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)\n",
    "y_test = data_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_digit(data_test, 2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(np.array([X_test[2005]]), optimal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(X, y, optimal_points):\n",
    "    y_pred = infer(X, optimal_points)\n",
    "    return np.sum(y_pred == y) / y.shape[0]\n",
    "evaluate(X_test, y_test, optimal_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immplementing the formula of softmax function to calculate the loss function for multiclass classification\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    return (np.exp(z).T / np.sum(np.exp(z), axis=0)).T\n",
    "\n",
    "class MulticlassRegression:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def loss_softmax(self, a: np.ndarray):\n",
    "        prob = softmax(np.dot(self.X, a))``\n",
    "        values = - np.log(prob[np.arrange(self.y.shape[0]), self.y])\n",
    "        return np.nansum(values) / self.y.shape[0]\n",
    "    \n",
    "    def gradient_softmax(self, a: np.ndarray):\n",
    "        prob = softmax(np.dot(self.X, a))\n",
    "        sub_coefficient = prob - self.y\n",
    "        return np.dot(self.X.T, sub_coefficient) / self.y.shape[0]\n",
    "    \n",
    "    def precision_softmax(self, a:np.ndarray):\n",
    "        prob = softmax(np.dot(self.X, a))\n",
    "        prob = np.argmax(prob, axis = 0)\n",
    "        return np.sum(prob == self.y) / self.y.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement focal loss to deal with the imbalanced data\n",
    "class FocalLoss:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def focal_loss(self, a:np.ndarray, gamma = 2, alpha = 0.25):\n",
    "        prob = softmax(np.dot(self.X, a))\n",
    "        values = - alpha * (1 - prob) ** gamma * np.log(prob)\n",
    "        return np.nansum(values) / self.y.shape[0]\n",
    "\n",
    "    def gradient_focal_loss(self, a:np.ndarray, gamma = 2, alpha = 0.25):\n",
    "        prob = softmax(np.dot(self.X, a))\n",
    "        sub_coefficient = - alpha * (1 - prob) ** gamma * (gamma * prob * np.log(prob) + prob - 1)\n",
    "        return np.dot(self.X.T, sub_coefficient) / self.y.shape[0]\n",
    "\n",
    "    def precision_focal_loss(self, a:np.ndarray):\n",
    "        prob = softmax(np.dot(self.X, a))\n",
    "        prob = np.argmax(prob, axis = 0)\n",
    "        return np.sum(prob == self.y) / self.y.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_functions = []\n",
    "for digit in range(10):\n",
    "    y_digit = np.array(y == digit, dtype=np.int32)\n",
    "    loss_functions.append(FocalLoss(X, y_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_softmax_process(loss_func, starting_point, learning_rate = 0.00001, num_steps = 40, precision=0.00001):\n",
    "    cur_point = starting_point\n",
    "    for i in range(num_steps):\n",
    "        grad = loss_func.gradient_focal_loss(cur_point)\n",
    "        cur_point = cur_point - learning_rate * grad\n",
    "        if np.linalg.norm(grad) < precision:\n",
    "            break\n",
    "    return cur_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for digit 0: 0.0\n",
      "Accuracy for digit 1: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for digit 2: 0.0\n",
      "Accuracy for digit 3: 0.0\n",
      "Accuracy for digit 4: 0.0\n",
      "Accuracy for digit 5: 0.0\n",
      "Accuracy for digit 6: 0.0\n",
      "Accuracy for digit 7: 0.0\n",
      "Accuracy for digit 8: 0.0\n",
      "Accuracy for digit 9: 0.0\n"
     ]
    }
   ],
   "source": [
    "optimal_points = []\n",
    "\n",
    "for digit in range(10):\n",
    "    optimal_point = gradient_softmax_process(loss_functions[digit], np.zeros(X.shape[1]))\n",
    "    print(\"Accuracy for digit {}: {}\".format(digit, loss_functions[digit].precision_focal_loss(optimal_point)))\n",
    "    optimal_points.append(optimal_point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
